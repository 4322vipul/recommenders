{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X80i_girFR2o"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "bB8gHCR3FVC0"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kCeYA79m1DEX"
      },
      "source": [
        "# Building complex features\n",
        "\n",
        "\u003ctable class=\"tfo-notebook-buttons\" align=\"left\"\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://www.tensorflow.org/recommenders/examples/movielens\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" /\u003eView on TensorFlow.org\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/recommenders/blob/main/docs/examples/featurization.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /\u003eRun in Google Colab\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://github.com/tensorflow/recommenders/blob/main/docs/examples/featurization.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /\u003eView source on GitHub\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca href=\"https://storage.googleapis.com/tensorflow_docs/recommenders/docs/examples/featurization.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/download_logo_32px.png\" /\u003eDownload notebook\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "\u003c/table\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TFJUp0Vdu-TG"
      },
      "source": [
        "One of the great advantages of usign a two-tower retrieval model built using a deep learning framework is the freedom to build rich, flexible feature representations.\n",
        "\n",
        "In this tutorial we are going to explore how to do this using TFRS.\n",
        "\n",
        "## The MovieLens dataset\n",
        "\n",
        "The [MovieLens dataset](https://grouplens.org/datasets/movielens/) gives us multiple features we can play with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BxQ_hy7xPH3N"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
        "\n",
        "for x in ratings.take(1).as_numpy_iterator():\n",
        "  pprint.pprint(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_6ypp_nVub8J"
      },
      "source": [
        "Few of these features are immediately usable in a deep learning model; we need  to process most of them to make them available to our model.\n",
        "\n",
        "In this tutorial, we're going to cover:\n",
        "\n",
        "1. how to process categorical features (for example, `movie_id` or `user_occupation`) into embeddings,\n",
        "2. how to normalize continuous features.\n",
        "\n",
        "We will use Keras feature processing components throughout. This has the key advantage of keeping feature processing consistent between training and serving time: we can be sure that whatever pre-processing we add in the training phase will be applied in exactly the same way at serving time. This makes deploying TensorFlow models straightforward, as we can send them raw features and serving time and be sure that they will do the right thing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cp2rd--gvW9w"
      },
      "source": [
        "## Turning categorical features into embeddings\n",
        "\n",
        "A [categorical feature](https://en.wikipedia.org/wiki/Categorical_variable) is a feature that does not express a continuous quantity, but rather takes on one of a set of fixed values. For example, the id or the title of a movie are categorical features.\n",
        "\n",
        "Most deep learning models express these feature by turning them into high-dimensional vectors. During model training, the value of that vector is adjusted to help the model predict its objective better.\n",
        "\n",
        "For example, suppose that our goal is to predict which user is going to watch which movie. To do that, we represent each user and each movie by an embedding vector. Initially, these embeddings will take on random values - but during training, we will adjust them so that embeddings of users and the movies they watch end up closer together.\n",
        "\n",
        "Taking raw categorical features and turning them into embeddings is normally a two-step process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aa-7so1D_9B2"
      },
      "source": [
        "### Defining the vocabulary\n",
        "\n",
        "The first step is to define a vocabulary: a mapping from the raw feature value (say, \"doctor\") to nonnegative integer.\n",
        "\n",
        "We can do this easily using Keras preprocessing layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IkA1HOXKyaEo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "movie_title_lookup = tf.keras.layers.experimental.preprocessing.StringLookup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7We60Iduy2SP"
      },
      "source": [
        "The layer itself does not have a vocabulary yet, but we can build it using our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GKluOy3ly7Pg"
      },
      "outputs": [],
      "source": [
        "movie_title_lookup.adapt(ratings.map(lambda x: x[\"movie_title\"]))\n",
        "\n",
        "print(f\"Vocabulary: {movie_title_lookup.get_vocabulary()[:3]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1cH2Je_KBQZy"
      },
      "source": [
        "Once we have this we can use the layer to translate raw tokens to embedding ids:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zXYpfmWDBVOq"
      },
      "outputs": [],
      "source": [
        "movie_title_lookup([\"Star Wars (1977)\", \"One Flew Over the Cuckoo's Nest (1975)\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PYXiq04dzTaq"
      },
      "source": [
        "Note that the layer's vocabulary includes one (or more!) unknown (or \"out of vocabulary\", OOV) tokens. This is really handy: it means that the layer can handle categorical values that are not in the vocabulary. In practical terms, this means that the model can continue to learn about and make recommendations even using features that have not been seen during vocabulary construction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qseZxzmBBJvv"
      },
      "source": [
        "### Using feature hashing\n",
        "\n",
        "In fact, the `StringLookup` layer allows us to configure multiple OOV indices. If we do that, any raw value that is not in the vocabulary will be deterministically hashed to one of the OOV indices. The more such indices we have, the less likley it is that two different raw feature values will hash to the same OOV index. Consequently, if we have enough such indices the model should be able to train about as well as a model with an explicit vocabulary without the disdvantage of having to maintain the token list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t0gOaMjJAC17"
      },
      "source": [
        "We can take this to its logical extreme and rely entirely on feature hashing, with no vocabulary at all. This is implemented in the `tf.keras.layers.experimental.preprocessing.Hashing` layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1Os5gwGxzSaG"
      },
      "outputs": [],
      "source": [
        "# We set up a large number of bins to reduce the chance of hash collisions.\n",
        "num_hashing_bins = 200_000\n",
        "\n",
        "movie_title_hashing = tf.keras.layers.experimental.preprocessing.Hashing(\n",
        "    num_bins=num_hashing_bins\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rvcVNCzNB8GE"
      },
      "source": [
        "We can do the lookup as before without the need to build vocabularies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OkEWdeflCAY6"
      },
      "outputs": [],
      "source": [
        "movie_title_hashing([\"Star Wars (1977)\", \"One Flew Over the Cuckoo's Nest (1975)\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-QFinPDA0LxM"
      },
      "source": [
        "### Defining the embeddings\n",
        "\n",
        "Now that we integer ids, we can use the [`Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) layer to turn those into embeddings.\n",
        "\n",
        "An embedding layer has two dimensions: the first dimension tells us how many distinct categories we can embed; the second tells us how large the vector representing each of them can be.\n",
        "\n",
        "When creating the embedding layer for movie titles, we are going to set the first value to the size of our title vocabulary (or the number of hashing bins). The second is up to us: the larger it is, the higher the capacity of the model, but the slower it is to fit and serve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "RUftFomv0nGO"
      },
      "outputs": [],
      "source": [
        "movie_title_embedding = tf.keras.layers.Embedding(\n",
        "    # Let's use the hashing approach.\n",
        "    input_dim=num_hashing_bins,\n",
        "    output_dim=32\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8JNyTTQq1RIw"
      },
      "source": [
        "We can put the two together into a single layer which takes raw text in and yields embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "RSbQd_mn1YYe"
      },
      "outputs": [],
      "source": [
        "movie_title_model = tf.keras.Sequential([movie_title_hashing, movie_title_embedding])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4QoA9YHw1gQc"
      },
      "source": [
        "Just like that, we can directly get the embeddings for our movie titles:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "T-s6uPqM1fZz"
      },
      "outputs": [],
      "source": [
        "movie_title_model([\"Star Wars (1977)\", \"One Flew Over the Cuckoo's Nest (1975)\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2chJv4jTSg04"
      },
      "source": [
        "We can do the same with user embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3ot3bfX8SgWT"
      },
      "outputs": [],
      "source": [
        "user_id_lookup = tf.keras.layers.experimental.preprocessing.Hashing(\n",
        "    num_bins=num_hashing_bins)\n",
        "user_id_embedding = tf.keras.layers.Embedding(num_hashing_bins, 32)\n",
        "\n",
        "user_id_model = tf.keras.Sequential([user_id_lookup, user_id_embedding])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "abZNsN3oDf1F"
      },
      "source": [
        "## Normalizing continuous features\n",
        "\n",
        "Continuous features also need normalization. For example, the `timestamp` feature is far too large to be used directly in a deep model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GGcKKOyLDsEY"
      },
      "outputs": [],
      "source": [
        "for x in ratings.take(3).as_numpy_iterator():\n",
        "  print(f\"Timestamp: {x['timestamp']}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4aL_GMuaEBy0"
      },
      "source": [
        "We need to process it before we can use it. While there are many ways in which we can do this, discretization and standardization are two common ones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iCe-ch7eENNR"
      },
      "source": [
        "### Standardization\n",
        "\n",
        "[Standardization](https://en.wikipedia.org/wiki/Feature_scaling#Standardization_(Z-score_Normalization)) rescales features to normalize their range by subtracting the feature's mean and dividing by its standard deviation. It is a common preprocessing transformation.\n",
        "\n",
        "This can be easily accomplished using the [`tf.keras.layers.experimental.preprocessing.Normalization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Normalization) layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WxPsx6iSLGrp"
      },
      "outputs": [],
      "source": [
        "timestamp_normalization = tf.keras.layers.experimental.preprocessing.Normalization()\n",
        "timestamp_normalization.adapt(ratings.map(lambda x: x[\"timestamp\"]).batch(1024))\n",
        "\n",
        "for x in ratings.take(3).as_numpy_iterator():\n",
        "  print(f\"Normalized timestamp: {timestamp_normalization(x['timestamp'])}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zW1B974ZPn71"
      },
      "source": [
        "### Discretization\n",
        "\n",
        "Another common transformation is to turn a continuous feature into a number of categorical features. This makes good sense if we have reasons to suspect that a feature's effect is non-continuous.\n",
        "\n",
        "To do this, we first need to establish the boundaries of the buckets we will use for discretization. The easiest way is to identify the minimum and maximum value of the feature, and divide the resulting interval equally:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YlJK0rYyQGEf"
      },
      "outputs": [],
      "source": [
        "max_timestamp = ratings.map(lambda x: x[\"timestamp\"]).reduce(\n",
        "    tf.cast(0, tf.int64), tf.maximum).numpy().max()\n",
        "min_timestamp = ratings.map(lambda x: x[\"timestamp\"]).reduce(\n",
        "    np.int64(1e9), tf.minimum).numpy().min()\n",
        "\n",
        "timestamp_buckets = np.linspace(\n",
        "    min_timestamp, max_timestamp, num=1000)\n",
        "\n",
        "print(f\"Buckets: {timestamp_buckets[:3]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iPS3fh5JQhkO"
      },
      "source": [
        "Given the bucket boundaries we can transform timestamps into embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "VCizNzPkQmwK"
      },
      "outputs": [],
      "source": [
        "timestamp_embedding_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.Discretization(timestamp_buckets.tolist()),\n",
        "  tf.keras.layers.Embedding(len(timestamp_buckets) + 2, 32)\n",
        "])\n",
        "\n",
        "for timestamp in ratings.take(1).map(lambda x: x[\"timestamp\"]).batch(1).as_numpy_iterator():\n",
        "  print(f\"Timestamp embedding: {timestamp_embedding_model(timestamp)}.\")                                       "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zbbsLtlF1ynV"
      },
      "source": [
        "## Training a model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d6t0kOC42sPn"
      },
      "source": [
        "With all these components present we can start building a model.\n",
        "\n",
        "First, we'll build a user model that incorporates both timestamp and user id information:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FyPZ-N35onkz"
      },
      "outputs": [],
      "source": [
        "class UserModel(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self._user_id_model = user_id_model\n",
        "    self._timestamp_embedding_model = timestamp_embedding_model\n",
        "    self._timestamp_normalization_model = timestamp_normalization\n",
        "    self._projection = tf.keras.layers.Dense(32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "\n",
        "    # Take the input dictionary, pass it through each input layer,\n",
        "    # and concatenate the result.\n",
        "    features = tf.concat([\n",
        "        self._user_id_model(inputs[\"user_id\"]),\n",
        "        self._timestamp_embedding_model(inputs[\"timestamp\"]),\n",
        "        self._timestamp_normalization_model(inputs[\"timestamp\"])\n",
        "    ], axis=1)\n",
        "\n",
        "    # We need to add a dense layer to ensure that the output dimension\n",
        "    # of the user model is the same as that of the movie model.\n",
        "    return self._projection(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wu0-QXd6qlJV"
      },
      "source": [
        "We can then set up the full model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pCO8KDGO2rb7"
      },
      "outputs": [],
      "source": [
        "import tensorflow_recommenders as tfrs\n",
        "\n",
        "\n",
        "class Model(tfrs.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.user_model = UserModel()\n",
        "    self.movie_model = movie_title_model\n",
        "    self.task = tfrs.tasks.RetrievalTask(\n",
        "        corpus_metrics=tfrs.metrics.FactorizedTopK(\n",
        "          candidates=movies.batch(128).map(lambda x: x[\"movie_title\"]).map(self.movie_model)\n",
        "        )\n",
        "    )\n",
        "\n",
        "  def compute_loss(self, features, training=False):\n",
        "    # We pick out the user features and pass them into the user model.\n",
        "    user_embeddings = self.user_model(\n",
        "        {k: v for k, v in features.items() if k in (\"timestamp\", \"user_id\")})\n",
        "    # And pick out the movie features and pass them into the movie model,\n",
        "    # getting embeddings back.\n",
        "    positive_movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
        "\n",
        "    # The task computes the loss and the metrics.\n",
        "    return self.task(user_embeddings, positive_movie_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NChzu1jfqrc2"
      },
      "source": [
        "Prepare the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WlCdIzip3LaF"
      },
      "outputs": [],
      "source": [
        "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
        "\n",
        "ratings = ratings.map(lambda x: {\n",
        "    \"movie_title\": x[\"movie_title\"],\n",
        "    \"user_id\": x[\"user_id\"],\n",
        "    \"timestamp\": x[\"timestamp\"]\n",
        "})\n",
        "movies = movies.map(lambda x: {\n",
        "    \"movie_title\": x[\"movie_title\"],\n",
        "})\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(80_000)\n",
        "test = shuffled.skip(80_000).take(20_000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "St4vMygx3nWL"
      },
      "outputs": [],
      "source": [
        "model = Model()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xwe9dei-qt08"
      },
      "source": [
        "Fit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "PiUECvUv3uGe"
      },
      "outputs": [],
      "source": [
        "model.fit(train.batch(4096), epochs=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "73nRhw81tDL_"
      },
      "source": [
        "And evaluate:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AgsXBLREtAyB"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test.batch(4096))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B4QABjnaKQea"
      },
      "source": [
        "## Serving a model\n",
        "\n",
        "Now that we have a model, let's prepare it for serving recommendations.\n",
        "\n",
        "The simplest way is to do this by brute force: when given a query, compute scores across all possible candidates, and return the top ones. Of course, this is only feasible when the candidate set is relatively small; however, it will serve for demonstration purposes here.\n",
        "\n",
        "We first precompute the candidate embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "KWZgSj3gLYyg"
      },
      "outputs": [],
      "source": [
        "movie_titles = np.concatenate(list(\n",
        "    movies.batch(1_000)\n",
        "    .map(lambda x: x[\"movie_title\"])\n",
        "))\n",
        "movie_embeddings = np.concatenate(list(\n",
        "    movies.batch(1_000)\n",
        "    .map(lambda x: model.movie_model(x[\"movie_title\"]))\n",
        "    .as_numpy_iterator()\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "srxosSnjNYgi"
      },
      "source": [
        "And then use those to create a new layer for serving recommendations using the `tfrs.layers.ann.BruteForce` layer.\n",
        "\n",
        "When constructing the layer, we will pass in the query model we just trained. By doing so, we make it possible for us to send raw query features to them model, and have the model automatically transform them into query embeddings. This is operationally very convenient, as it (1) makes sure we use the same feature processing in serving as we do in training, and (2) eliminates the need to maintain separate query models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "KRzJt5msN1Ld"
      },
      "outputs": [],
      "source": [
        "serving_model = tfrs.layers.ann.BruteForce(model.user_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_3PLAiD6N3tU"
      },
      "source": [
        "Once we have the layer, we need to index it with the candidate embeddings we want to use. When calling the `index` method we pass movie titles as the identifiers argument. That way, when we issue a query we will get the movie titles of top recommended movies back (instead of more opaque identifiers we would have to post-process later):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "y3RJRmfy5A7b"
      },
      "outputs": [],
      "source": [
        "movie_titles = movies.map(lambda x: x[\"movie_title\"])\n",
        "\n",
        "serving_model.index(\n",
        "    candidates=movie_titles.batch(128).map(model.movie_model),\n",
        "    identifiers=movie_titles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UXwbLzJWOKIO"
      },
      "source": [
        "With this, we're ready to get our recommendations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IJ_nyIfiKwSA"
      },
      "outputs": [],
      "source": [
        "scores, titles = serving_model(\n",
        "    {\"user_id\": np.array([\"42\"]), \"timestamp\": np.array([879024327])},\n",
        "    num_candidates=3\n",
        ")\n",
        "print(f\"Top recommendations: {titles.numpy().tolist()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cMMEgoyUPRyM"
      },
      "source": [
        "Once saved and restored, this model can be used in any TensorFlow serving infrastructure (such as [TensorFlow Serving](https://www.tensorflow.org/tfx/tutorials/serving/rest_simple) or your own microservice)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "vhuGODbBLTwW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile\n",
        "\n",
        "tmp = tempfile.TemporaryDirectory()\n",
        "\n",
        "path = os.path.join(tmp.name, \"model\")\n",
        "tf.saved_model.save(serving_model, path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ZgOLvdoyP6E6"
      },
      "outputs": [],
      "source": [
        "loaded = tf.keras.models.load_model(path)\n",
        "\n",
        "scores, titles = loaded(\n",
        "    {\"user_id\": np.array([\"42\"]), \"timestamp\": np.array([879024327])},\n",
        ")\n",
        "print(f\"Top recommendations: {titles.numpy().tolist()[0][:3]}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "featurization.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
