{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_recommenders.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikhIvrku-i-L",
        "colab_type": "text"
      },
      "source": [
        "# Using deep models in retrieval\n",
        "\n",
        "In [the featurization tutorial](https://github.com/tensorflow/recommenders/blob/main/docs/examples/featurization.ipynb) we incorporated multiple features into our models, but the models consist of only an embedding layer. We can add more dense layers to our models to increase their capacity.\n",
        "\n",
        "Deep models with multiple layers can approximate more complex patterns and functions than models with only an embedding layer. Furthermore, with more layers, the learnability of the model might also improve. While model with one hidden layer can approximate any function in theory, in practice models with more hidden layers can learn to approximate complex functions more easily.\n",
        "\n",
        "Nonetheless, complex models also have their disadvantages. More layers require more training epochs, and each training step would require more computation. It would also be harder for the gradients to propagate through models with more layers when updating model parameters. Furthermore, with more parameters, deep models might overfit or even simply memorize the training examples instead of learning a function that can generalize.\n",
        "\n",
        "In this notebook we will build deep models with multiple layers and compare the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7RYXwgbAcbU",
        "colab_type": "text"
      },
      "source": [
        "## Preliminaries\n",
        "\n",
        "We first import the necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbwMjnLP5nZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tempfile\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import tensorflow_recommenders as tfrs"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgKIjpQLAiax",
        "colab_type": "text"
      },
      "source": [
        "In this tutorial we will use the models from [the featurization tutorial](https://github.com/tensorflow/recommenders/blob/main/docs/examples/featurization.ipynb) to generate embeddings. Hence we will only be using the user id, timestamp, and movie title features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc2REbOO52Fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
        "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
        "\n",
        "ratings = ratings.map(lambda x: {\n",
        "    \"movie_title\": x[\"movie_title\"],\n",
        "    \"user_id\": x[\"user_id\"],\n",
        "    \"timestamp\": x[\"timestamp\"],\n",
        "})\n",
        "movies = movies.map(lambda x: {\n",
        "    \"movie_title\": x[\"movie_title\"],\n",
        "})"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YZ2q5RXYNI6",
        "colab_type": "text"
      },
      "source": [
        "We bucketize the timestamp feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5CVveCS9Doq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_timestamp = ratings.map(lambda x: x[\"timestamp\"]).reduce(\n",
        "    tf.cast(0, tf.int64), tf.maximum).numpy().max()\n",
        "min_timestamp = ratings.map(lambda x: x[\"timestamp\"]).reduce(\n",
        "    np.int64(1e9), tf.minimum).numpy().min()\n",
        "timestamp_buckets = np.linspace(\n",
        "    min_timestamp, max_timestamp, num=1000,\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFJcCVMUQou3",
        "colab_type": "text"
      },
      "source": [
        "## Model definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtS6a4sgmI-c",
        "colab_type": "text"
      },
      "source": [
        "### Query model\n",
        "\n",
        "We will define a generic query model that can have different architectures depending on the constructor arguments.\n",
        "\n",
        "We will use the user model defined in [the featurization tutorial](https://github.com/tensorflow/recommenders/blob/main/docs/examples/featurization.ipynb) as a component of our query model. It will convert input examples into feature embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ItzYwMW42cb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UserModel(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    num_hashing_bins = 20_000\n",
        "\n",
        "    self.user_embedding = tf.keras.Sequential([\n",
        "        tf.keras.layers.experimental.preprocessing.Hashing(num_bins=num_hashing_bins),\n",
        "        tf.keras.layers.Embedding(num_hashing_bins, 32),\n",
        "    ])\n",
        "    self.timestamp_embedding = tf.keras.Sequential([\n",
        "        tf.keras.layers.experimental.preprocessing.Discretization(timestamp_buckets.tolist()),\n",
        "        tf.keras.layers.Embedding(len(timestamp_buckets) + 2, 32),\n",
        "    ])\n",
        "    self.normalized_timestamp = tf.keras.layers.experimental.preprocessing.Normalization()\n",
        "\n",
        "  def call(self, inputs):\n",
        "\n",
        "    # Take the input dictionary, pass it through each input layer,\n",
        "    # and concatenate the result.\n",
        "    return tf.concat([\n",
        "        self.user_embedding(inputs[\"user_id\"]),\n",
        "        self.timestamp_embedding(inputs[\"timestamp\"]),\n",
        "        self.normalized_timestamp(inputs[\"timestamp\"]),\n",
        "    ], axis=1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMQzxLqh42on",
        "colab_type": "text"
      },
      "source": [
        "In addition to the embedding model, we also add hidden layers according to the argument `hidden_layer_sizes` to make the query model deep and use activation functions specified by the argument `activation`. After adding the hidden layers, we add a projection layer to generate embeddings of dimensionality specified by `final_embedding_dimension`.\n",
        "\n",
        "Note that we do not use any activation function on the projection layer. Using an activation function would limit the output space of the final embeddings and might negatively impact the performance of the model. For instance, if ReLUs are used in the projection layer, all components in the output embedding would be non-negative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qfPi4I-Z0ph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QueryModel(tf.keras.Model):\n",
        "  \"\"\"Model for encoding user queries.\"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      final_embedding_dimension,\n",
        "      hidden_layer_sizes=None,\n",
        "      activation=None,\n",
        "  ):\n",
        "    \"\"\"Initializes a query model for encoding user queries.\n",
        "\n",
        "    Args:\n",
        "      final_embedding_dimension:\n",
        "        An integer representing the dimensionality of the final embedding. The\n",
        "        model would add a final projection layer with\n",
        "        `final_embedding_dimension` units to ensure that the output embedding\n",
        "        has the specified number of dimensions.\n",
        "      hidden_layer_sizes:\n",
        "        A list of integers where the ith entry represents the number of units\n",
        "        the ith layer contains.\n",
        "      activation:\n",
        "        A string representing the activation function to be used in all layers\n",
        "        except the last layer. It will be passed to `tf.keras.layers.Dense` as\n",
        "        an argument. If activation is None, then no activation function is used.\n",
        "    \n",
        "    Returns:\n",
        "      A query model for encoding queries.\n",
        "    \"\"\"\n",
        "    super(QueryModel, self).__init__()\n",
        "\n",
        "    if hidden_layer_sizes is None:\n",
        "      hidden_layer_sizes = []\n",
        "\n",
        "    # We first use the user model for generating embeddings.\n",
        "    self.embedding_model = UserModel()\n",
        "\n",
        "    dense_layer_list = []\n",
        "    # We now add the hidden layers.\n",
        "    for layer_size in hidden_layer_sizes:\n",
        "      dense_layer_list.append(\n",
        "          tf.keras.layers.Dense(layer_size, activation=activation),\n",
        "      )\n",
        "    # We finally add a projection layer without any activation function.\n",
        "    dense_layer_list.append(\n",
        "        tf.keras.layers.Dense(final_embedding_dimension, activation=None),\n",
        "    )\n",
        "    self.dense_layers = tf.keras.Sequential(dense_layer_list, name='dense_layers')\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    feature_embedding = self.embedding_model(inputs)\n",
        "    return self.dense_layers(feature_embedding)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XleMceZNHC__",
        "colab_type": "text"
      },
      "source": [
        "### Candidate model\n",
        "\n",
        "Since we are focusing on exploring different query models, we will keep the candidate model simple and use only the embedding model from [the featurization tutorial](https://github.com/tensorflow/recommenders/blob/main/docs/examples/featurization.ipynb). Note that this model generates embeddings with 64 dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQZHX8bEHPOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MovieModel(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    num_hashing_bins = 20_000\n",
        "    max_tokens = 10_000\n",
        "\n",
        "    self.title_embedding = tf.keras.Sequential([\n",
        "      tf.keras.layers.experimental.preprocessing.Hashing(num_bins=num_hashing_bins),\n",
        "      tf.keras.layers.Embedding(num_hashing_bins, 32)\n",
        "    ])\n",
        "    self.title_text_embedding = tf.keras.Sequential([\n",
        "      tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=max_tokens),\n",
        "      tf.keras.layers.Embedding(max_tokens, 32)\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return tf.concat([\n",
        "        self.title_embedding(inputs[\"movie_title\"]),\n",
        "        # We average the embedding of individual words to get one embedding vector\n",
        "        # per title.\n",
        "        tf.reduce_mean(self.title_text_embedding(inputs[\"movie_title\"]), axis=-2),\n",
        "    ], axis=1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cc4KbTNwHSvD",
        "colab_type": "text"
      },
      "source": [
        "### Combined model\n",
        "\n",
        "We now define a combined model that takes a query model and a candidate model as arguments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26_hNJPKIh4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MovielensModel(tfrs.models.Model):\n",
        "\n",
        "  def __init__(self, query_model, candidate_model):\n",
        "    super().__init__()\n",
        "    self.query_model: tf.keras.Model = query_model\n",
        "    self.candidate_model: tf.keras.Model = candidate_model\n",
        "    self.task = tfrs.tasks.Retrieval(\n",
        "        metrics=tfrs.metrics.FactorizedTopK(\n",
        "            candidates=movies.batch(128).map(self.candidate_model),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "  def compute_loss(self, features, training=False):\n",
        "    # We only pass the user id and timestamp features into the query model. This\n",
        "    # is to ensure that the training inputs would have the same keys as the\n",
        "    # query inputs. Otherwise the discrepancy in input structure would cause an\n",
        "    # error when loading the query model after saving it.\n",
        "    query_embeddings = self.query_model({\n",
        "        \"user_id\": features[\"user_id\"],\n",
        "        \"timestamp\": features[\"timestamp\"],\n",
        "    })\n",
        "    positive_movie_embeddings = self.candidate_model({\n",
        "        \"movie_title\": features[\"movie_title\"],\n",
        "    })\n",
        "    return self.task(query_embeddings, positive_movie_embeddings, training=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YXjsRsLTVzt",
        "colab_type": "text"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY7MTwMruoKh",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the data\n",
        "\n",
        "We first split the data into a training set and a testing set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMFUZ4dyTdYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(80_000)\n",
        "test = shuffled.skip(80_000).take(20_000)\n",
        "\n",
        "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
        "cached_test = test.batch(4096).cache()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2HEuTBzJ9w5",
        "colab_type": "text"
      },
      "source": [
        "### Model with one dense layer\n",
        "\n",
        "We now define the dimensionalities of the final embeddings below. Since `MovieModel` generates embeddings with 64 dimensions, we want our query models to generate 64 dimensional embeddings as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xysGAeOyQd0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_embedding_dimension = 64"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WECDQLtQzts",
        "colab_type": "text"
      },
      "source": [
        "We now define a simple model with only a projection layer and no hidden layer. The activation function does not matter since the projection layer does not have any activation function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkoLkiQdK4Um",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_layer_query_model = QueryModel(\n",
        "    final_embedding_dimension,\n",
        ")\n",
        "one_layer_candidate_model = MovieModel()\n",
        "one_layer_candidate_model.title_text_embedding.layers[0].adapt(\n",
        "    movies.map(lambda x: x[\"movie_title\"]),\n",
        ")\n",
        "one_layer_model = MovielensModel(\n",
        "    one_layer_query_model,\n",
        "    one_layer_candidate_model,\n",
        ")\n",
        "one_layer_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LicXTr1vLA-L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "9a8343e3-8222-4cd0-dd14-3e77a643aeb2"
      },
      "source": [
        "one_layer_model.fit(cached_train, epochs=3)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "10/10 [==============================] - 21s 2s/step - factorized_top_k: 2.1250e-04 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 1.2500e-04 - factorized_top_k/top_100_categorical_accuracy: 9.3750e-04 - loss: 639008857367.2727 - regularization_loss: 0.0000e+00 - total_loss: 639008857367.2727\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 18s 2s/step - factorized_top_k: 0.0015 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 6.2500e-05 - factorized_top_k/top_10_categorical_accuracy: 8.7500e-05 - factorized_top_k/top_50_categorical_accuracy: 9.0000e-04 - factorized_top_k/top_100_categorical_accuracy: 0.0066 - loss: 494642662306.9091 - regularization_loss: 0.0000e+00 - total_loss: 494642662306.9091\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 18s 2s/step - factorized_top_k: 0.0069 - factorized_top_k/top_1_categorical_accuracy: 5.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 1.8750e-04 - factorized_top_k/top_10_categorical_accuracy: 4.1250e-04 - factorized_top_k/top_50_categorical_accuracy: 0.0070 - factorized_top_k/top_100_categorical_accuracy: 0.0269 - loss: 334697702120.7273 - regularization_loss: 0.0000e+00 - total_loss: 334697702120.7273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f137e49e048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjJ1anzuLXgN",
        "colab_type": "text"
      },
      "source": [
        "### Model with three dense layers and no activation function\n",
        "\n",
        "We now create and train a model with two hidden layers of size 64 and one projection layer and no activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11qAr5gGMUxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "three_layer_query_model = QueryModel(\n",
        "    final_embedding_dimension,\n",
        "    hidden_layer_sizes=[64, 64],\n",
        "    activation=None,\n",
        ")\n",
        "three_layer_candidate_model = MovieModel()\n",
        "three_layer_candidate_model.title_text_embedding.layers[0].adapt(\n",
        "    movies.map(lambda x: x[\"movie_title\"]),\n",
        ")\n",
        "three_layer_model = MovielensModel(\n",
        "    three_layer_query_model,\n",
        "    three_layer_candidate_model,\n",
        ")\n",
        "three_layer_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nqR-97yk63H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "72dd90ee-8ee1-4bb8-8d5b-f7ff2e89972f"
      },
      "source": [
        "three_layer_model.fit(cached_train, epochs=3)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "10/10 [==============================] - 20s 2s/step - factorized_top_k_1: 0.0018 - factorized_top_k_1/top_1_categorical_accuracy: 1.2500e-05 - factorized_top_k_1/top_5_categorical_accuracy: 8.7500e-05 - factorized_top_k_1/top_10_categorical_accuracy: 2.5000e-04 - factorized_top_k_1/top_50_categorical_accuracy: 0.0023 - factorized_top_k_1/top_100_categorical_accuracy: 0.0064 - loss: 43854249161821.0938 - regularization_loss: 0.0000e+00 - total_loss: 43854249161821.0938\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 21s 2s/step - factorized_top_k_1: 0.0052 - factorized_top_k_1/top_1_categorical_accuracy: 6.2500e-05 - factorized_top_k_1/top_5_categorical_accuracy: 3.1250e-04 - factorized_top_k_1/top_10_categorical_accuracy: 0.0011 - factorized_top_k_1/top_50_categorical_accuracy: 0.0067 - factorized_top_k_1/top_100_categorical_accuracy: 0.0177 - loss: 3639035518231.2729 - regularization_loss: 0.0000e+00 - total_loss: 3639035518231.2729\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 19s 2s/step - factorized_top_k_1: 0.0089 - factorized_top_k_1/top_1_categorical_accuracy: 8.7500e-05 - factorized_top_k_1/top_5_categorical_accuracy: 4.1250e-04 - factorized_top_k_1/top_10_categorical_accuracy: 0.0013 - factorized_top_k_1/top_50_categorical_accuracy: 0.0128 - factorized_top_k_1/top_100_categorical_accuracy: 0.0297 - loss: 813895814050.9091 - regularization_loss: 0.0000e+00 - total_loss: 813895814050.9091\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f135f312320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwNey8NJpsqH",
        "colab_type": "text"
      },
      "source": [
        "### Model with five dense layers and no activation function\n",
        "\n",
        "We now create a model with four hidden layers of sizes 128, 128, 64, 64, and a projection layer and no activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi-KduIepzUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "five_layer_query_model = QueryModel(\n",
        "    final_embedding_dimension,\n",
        "    hidden_layer_sizes=[128, 128, 64, 64],\n",
        "    activation=None,\n",
        ")\n",
        "five_layer_candidate_model = MovieModel()\n",
        "five_layer_candidate_model.title_text_embedding.layers[0].adapt(\n",
        "    movies.map(lambda x: x[\"movie_title\"]),\n",
        ")\n",
        "five_layer_model = MovielensModel(\n",
        "    five_layer_query_model,\n",
        "    five_layer_candidate_model,\n",
        ")\n",
        "five_layer_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqFBowJ0p7Pr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "66bf4710-74c9-4169-e03a-00371ff77f52"
      },
      "source": [
        "five_layer_model.fit(cached_train, epochs=3)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "10/10 [==============================] - 20s 2s/step - factorized_top_k_2: 0.0017 - factorized_top_k_2/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k_2/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k_2/top_10_categorical_accuracy: 2.1250e-04 - factorized_top_k_2/top_50_categorical_accuracy: 0.0026 - factorized_top_k_2/top_100_categorical_accuracy: 0.0057 - loss: 5755433769405347.0000 - regularization_loss: 0.0000e+00 - total_loss: 5755433769405347.0000\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 19s 2s/step - factorized_top_k_2: 0.0112 - factorized_top_k_2/top_1_categorical_accuracy: 5.0000e-05 - factorized_top_k_2/top_5_categorical_accuracy: 4.6250e-04 - factorized_top_k_2/top_10_categorical_accuracy: 0.0022 - factorized_top_k_2/top_50_categorical_accuracy: 0.0168 - factorized_top_k_2/top_100_categorical_accuracy: 0.0367 - loss: 671937805061026.8750 - regularization_loss: 0.0000e+00 - total_loss: 671937805061026.8750\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 19s 2s/step - factorized_top_k_2: 0.0182 - factorized_top_k_2/top_1_categorical_accuracy: 1.2500e-05 - factorized_top_k_2/top_5_categorical_accuracy: 5.7500e-04 - factorized_top_k_2/top_10_categorical_accuracy: 0.0020 - factorized_top_k_2/top_50_categorical_accuracy: 0.0238 - factorized_top_k_2/top_100_categorical_accuracy: 0.0647 - loss: 111906700203845.8125 - regularization_loss: 0.0000e+00 - total_loss: 111906700203845.8125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f137c900da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdzm2cIOraFy",
        "colab_type": "text"
      },
      "source": [
        "### Model with three dense layers and ReLU activation function\n",
        "\n",
        "We now create a train a model with two hidden layers of size 64 and a projection layer. We use ReLUs in the hidden layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-rv2w8im5B6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "three_layer_relu_query_model = QueryModel(\n",
        "    final_embedding_dimension,\n",
        "    hidden_layer_sizes=[64, 64],\n",
        "    activation=\"relu\",\n",
        ")\n",
        "three_layer_relu_candidate_model = MovieModel()\n",
        "three_layer_relu_candidate_model.title_text_embedding.layers[0].adapt(\n",
        "    movies.map(lambda x: x[\"movie_title\"]),\n",
        ")\n",
        "three_layer_relu_model = MovielensModel(\n",
        "    three_layer_relu_query_model,\n",
        "    three_layer_relu_candidate_model,\n",
        ")\n",
        "three_layer_relu_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQChYfUYm5Ik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "7be05696-93e6-462e-f386-5f2800f0cab8"
      },
      "source": [
        "three_layer_relu_model.fit(cached_train, epochs=3)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "10/10 [==============================] - 20s 2s/step - factorized_top_k_3: 0.0148 - factorized_top_k_3/top_1_categorical_accuracy: 2.3750e-04 - factorized_top_k_3/top_5_categorical_accuracy: 0.0015 - factorized_top_k_3/top_10_categorical_accuracy: 0.0020 - factorized_top_k_3/top_50_categorical_accuracy: 0.0236 - factorized_top_k_3/top_100_categorical_accuracy: 0.0465 - loss: 705679185474.3508 - regularization_loss: 0.0000e+00 - total_loss: 705679185474.3508\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 18s 2s/step - factorized_top_k_3: 0.0135 - factorized_top_k_3/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k_3/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k_3/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k_3/top_50_categorical_accuracy: 0.0234 - factorized_top_k_3/top_100_categorical_accuracy: 0.0443 - loss: 70371.9474 - regularization_loss: 0.0000e+00 - total_loss: 70371.9474\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 18s 2s/step - factorized_top_k_3: 0.0147 - factorized_top_k_3/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k_3/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k_3/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k_3/top_50_categorical_accuracy: 0.0270 - factorized_top_k_3/top_100_categorical_accuracy: 0.0465 - loss: 70371.6222 - regularization_loss: 0.0000e+00 - total_loss: 70371.6222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f137b65af60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Yw1PeInSh8h",
        "colab_type": "text"
      },
      "source": [
        "## Comparing the models\n",
        "\n",
        "We now evaluate the four models and compare their results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g-hcYd_Beqp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "c5522e35-d368-4d1a-ff91-284b65c23a1d"
      },
      "source": [
        "one_layer_model.evaluate(cached_test, return_dict=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 4s 706ms/step - factorized_top_k: 0.0291 - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0010 - factorized_top_k/top_10_categorical_accuracy: 0.0023 - factorized_top_k/top_50_categorical_accuracy: 0.0413 - factorized_top_k/top_100_categorical_accuracy: 0.1006 - loss: 156813167274.6667 - regularization_loss: 0.0000e+00 - total_loss: 156813167274.6667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'factorized_top_k': array([0.     , 0.00105, 0.0023 , 0.04135, 0.1006 ], dtype=float32),\n",
              " 'factorized_top_k/top_100_categorical_accuracy': 0.1005999967455864,\n",
              " 'factorized_top_k/top_10_categorical_accuracy': 0.002300000051036477,\n",
              " 'factorized_top_k/top_1_categorical_accuracy': 0.0,\n",
              " 'factorized_top_k/top_50_categorical_accuracy': 0.041349999606609344,\n",
              " 'factorized_top_k/top_5_categorical_accuracy': 0.0010499999625608325,\n",
              " 'loss': 153423282176.0,\n",
              " 'regularization_loss': 0,\n",
              " 'total_loss': 153423282176.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "js2RjZQnozB0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "01bfc09a-70d8-4151-f058-ff350968841e"
      },
      "source": [
        "three_layer_model.evaluate(cached_test, return_dict=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 3s 667ms/step - factorized_top_k_1: 0.0327 - factorized_top_k_1/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k_1/top_5_categorical_accuracy: 7.0000e-04 - factorized_top_k_1/top_10_categorical_accuracy: 0.0041 - factorized_top_k_1/top_50_categorical_accuracy: 0.0483 - factorized_top_k_1/top_100_categorical_accuracy: 0.1102 - loss: 124413053610.6667 - regularization_loss: 0.0000e+00 - total_loss: 124413053610.6667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'factorized_top_k_1': array([0.     , 0.0007 , 0.0041 , 0.04835, 0.11015], dtype=float32),\n",
              " 'factorized_top_k_1/top_100_categorical_accuracy': 0.11015000194311142,\n",
              " 'factorized_top_k_1/top_10_categorical_accuracy': 0.004100000020116568,\n",
              " 'factorized_top_k_1/top_1_categorical_accuracy': 0.0,\n",
              " 'factorized_top_k_1/top_50_categorical_accuracy': 0.04834999889135361,\n",
              " 'factorized_top_k_1/top_5_categorical_accuracy': 0.000699999975040555,\n",
              " 'loss': 89817063424.0,\n",
              " 'regularization_loss': 0,\n",
              " 'total_loss': 89817063424.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9KUQM4Do0n4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "01c84013-0f3d-4e6e-907b-040b5aa4698b"
      },
      "source": [
        "five_layer_model.evaluate(cached_test, return_dict=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 3s 641ms/step - factorized_top_k_2: 0.0222 - factorized_top_k_2/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k_2/top_5_categorical_accuracy: 4.5000e-04 - factorized_top_k_2/top_10_categorical_accuracy: 0.0038 - factorized_top_k_2/top_50_categorical_accuracy: 0.0349 - factorized_top_k_2/top_100_categorical_accuracy: 0.0719 - loss: 20117024582314.6680 - regularization_loss: 0.0000e+00 - total_loss: 20117024582314.6680\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'factorized_top_k_2': array([0.     , 0.00045, 0.00385, 0.03495, 0.0719 ], dtype=float32),\n",
              " 'factorized_top_k_2/top_100_categorical_accuracy': 0.07190000265836716,\n",
              " 'factorized_top_k_2/top_10_categorical_accuracy': 0.0038499999791383743,\n",
              " 'factorized_top_k_2/top_1_categorical_accuracy': 0.0,\n",
              " 'factorized_top_k_2/top_50_categorical_accuracy': 0.034949999302625656,\n",
              " 'factorized_top_k_2/top_5_categorical_accuracy': 0.00044999999227002263,\n",
              " 'loss': 18365051568128.0,\n",
              " 'regularization_loss': 0,\n",
              " 'total_loss': 18365051568128.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h25QO5cro1lH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "00781e18-089c-4ea0-c831-e3dcbd5553ae"
      },
      "source": [
        "three_layer_relu_model.evaluate(cached_test, return_dict=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 3s 636ms/step - factorized_top_k_3: 0.0156 - factorized_top_k_3/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k_3/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k_3/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k_3/top_50_categorical_accuracy: 0.0308 - factorized_top_k_3/top_100_categorical_accuracy: 0.0472 - loss: 32590.7090 - regularization_loss: 0.0000e+00 - total_loss: 32590.7090\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'factorized_top_k_3': array([0.     , 0.     , 0.     , 0.0308 , 0.04725], dtype=float32),\n",
              " 'factorized_top_k_3/top_100_categorical_accuracy': 0.04724999889731407,\n",
              " 'factorized_top_k_3/top_10_categorical_accuracy': 0.0,\n",
              " 'factorized_top_k_3/top_1_categorical_accuracy': 0.0,\n",
              " 'factorized_top_k_3/top_50_categorical_accuracy': 0.030799999833106995,\n",
              " 'factorized_top_k_3/top_5_categorical_accuracy': 0.0,\n",
              " 'loss': 29628.37109375,\n",
              " 'regularization_loss': 0,\n",
              " 'total_loss': 29628.37109375}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUNC9D70vhrp",
        "colab_type": "text"
      },
      "source": [
        "For all values of k except five, the three layer model with no activation function has the highest top k categorical accuracy. This shows that having multiple layers in a model can improve its performance as the three layer model outperformed the one layer model. However, the performance of the five layer model shows that a more complex model does not always guarantee better performance. As mentioned above, complex models require more training epochs. In this case, three epochs might not be sufficient for a five layer model.\n",
        "\n",
        "Note that the three layer model with ReLUs also performs worse than the three layer model without any activation function. This shows how activation can also affect model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTJeAkgcxhF0",
        "colab_type": "text"
      },
      "source": [
        "## Serving the model\n",
        "\n",
        "We now serve our best performing model, the three layer model. In a simple recommendation model, when receiving a query, we simply compute the embedding of the query and find the movies with the closest embeddings to that query. For efficiency, we can precompute the embeddings of all candidates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb3vp9NSh9hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie_embeddings = movies.batch(1_000).map(lambda x: three_layer_model.candidate_model(x))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV7_1LeziTWl",
        "colab_type": "text"
      },
      "source": [
        "To create a recommendation model that takes a query and returns the top candidates, we use the `ann` module in TFRS. Since the number of movies in the dataset is small, we can use the `BruteForce` layer to look for top candidates. We pass in the query model as an argument for encoding input queries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Pr0t8HhfITF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "serving_model = tfrs.layers.ann.BruteForce(three_layer_model.query_model)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MalSkARrjZw_",
        "colab_type": "text"
      },
      "source": [
        "We then let the recommendation model index the candidates by calling `index` and pass in the movie embeddings we precomputed and the movie titles as identifiers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wHlLW_6jjt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "serving_model.index(\n",
        "    candidates=movie_embeddings,\n",
        "    identifiers=movies.batch(1_000).map(lambda x: x[\"movie_title\"]),\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai5jg3QNqaPh",
        "colab_type": "text"
      },
      "source": [
        "We can query the model for recommendations by passing in a dictionary of features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JipvUA_nqZk8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "11acfd18-5352-4c88-e476-b54c950d0f14"
      },
      "source": [
        "scores, titles = serving_model(\n",
        "    {\"user_id\": np.array([\"42\"]), \"timestamp\": np.array([879024327])},\n",
        "    num_candidates=3,\n",
        ")\n",
        "for i, title in enumerate(titles[0].numpy().tolist()):\n",
        "  print(\"{:d}. {:s}\".format(i + 1, str(title)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1. b'Shall We Dance? (1937)'\n",
            "2. b'Dear God (1996)'\n",
            "3. b'Blue Angel, The (Blaue Engel, Der) (1930)'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqAFMrx7pua3",
        "colab_type": "text"
      },
      "source": [
        "We can save the model using `tf.saved_model.save`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIbfl_Q4qE2h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "f749b150-0289-44ef-8b3d-2e47d917e4d4"
      },
      "source": [
        "tmp = tempfile.TemporaryDirectory()\n",
        "path = os.path.join(tmp.name, \"s_model\")\n",
        "tf.saved_model.save(serving_model, path)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpnpn52hxo/s_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpnpn52hxo/s_model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_y7kJfcqh1X",
        "colab_type": "text"
      },
      "source": [
        "We can then load the model using `tf.keras.models.load_model`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27-o0wePqgnJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "04be3d5d-4c05-4ec2-fe7d-e9080085ca7b"
      },
      "source": [
        "loaded_model = tf.keras.models.load_model(path)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHv-AQbi-wl0",
        "colab_type": "text"
      },
      "source": [
        "We can query the loaded model for recommendations by passing in a dictionary of features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys5fl6brnS7C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "db739455-c8cc-4dda-c9b7-4949c7ce5f96"
      },
      "source": [
        "scores, titles = loaded_model(\n",
        "    {\"user_id\": np.array([\"42\"]), \"timestamp\": np.array([879024327])}\n",
        ")\n",
        "for i, title in enumerate(titles[0].numpy().tolist()):\n",
        "  print(\"{:d}. {:s}\".format(i + 1, str(title)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1. b'Shall We Dance? (1937)'\n",
            "2. b'Dear God (1996)'\n",
            "3. b'Blue Angel, The (Blaue Engel, Der) (1930)'\n",
            "4. b'Bottle Rocket (1996)'\n",
            "5. b'His Girl Friday (1940)'\n",
            "6. b'Set It Off (1996)'\n",
            "7. b'Wild America (1997)'\n",
            "8. b'Cape Fear (1962)'\n",
            "9. b'Sleepers (1996)'\n",
            "10. b'Soul Food (1997)'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB09crfpgBx7",
        "colab_type": "text"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "In this tutorial we expanded our retrieval model with dense layers and activation functions. To see how to create a model that can perform not only retrieval tasks but also rating tasks, take a look at [the multitask tutorial](https://github.com/tensorflow/recommenders/blob/main/docs/examples/multitask.ipynb)."
      ]
    }
  ]
}